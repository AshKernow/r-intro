---
title: "Introduction to Solving Biological Problems Using R - Day 2"
author: Mark Dunning and Aiora Zabala. Original material by Robert Stojnić, Laurent Gatto, Rob Foy
  John Davey, Dávid Molnár and Ian Roberts
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output: slidy_presentation
toc: yes
---

## Day 2 Schedule

1. Further customisation of plots
2. Statistics
3. Report-writing
4. Programming Techniques
5. Data analysis report

#1. Further customisation of plots

## Recap

- we have seen how to use `plot`, `boxplot` `hist` to make simple plots
- these come with arguments that can be used to change the appearance of the plot
    + `col`, `pch`
    + `main`, `xlab`, `ylab`
    + etc....
- we will now look at ways to modify the plot appearance after it has been created

## The painter's model

- R employs a painter's model to construct it's plots
- Elements of the graph are added to the canvas one layer at a time, and the picture built up in levels. Lower levels are obscured by higher levels, allowing for blending, masking and overlaying of objects.

##Initial plot

- Recall our weather dataset from yesterday

```{r}
data <- read.csv("Day_1_scripts/ozone.csv")
plot(data$Ozone, data$Solar.R,pch=16)
```

##The points function

- `points` can be used to set of points to an *existing* plot
- it requires a vector of x and y coordinates
    + these do not have to be the same length as the number of points in the initial plot
        + hence we can use `points` to highlight observations
        + or add a set of new observations
- Note that axis limits of the existing plot are not altered

```{r}
plot(data$Ozone, data$Solar.R,pch=16)
points(c(100,150),c(50,100))

```


##Adding points

```{r}
data <- read.csv("Day_1_scripts/ozone.csv")
plot(data$Ozone, data$Solar.R,pch=16)
points(data$Ozone, data$Wind)
```

##Adding points

`points` can also use the `pch`, `col` arguments. Useful for distinguishing between variables

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Solar.R,pch=16)
points(data$Ozone, data$Wind,pch=15,col="red")
```


##Adding points

- Each set of points can have a different colour and shape
- Axis labels and title and limits are defined by the plot
- You can add points ad-nauseum. Try not to make the plot cluttered!
- A call to `plot` will start a new graphics window

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Solar.R,pch=16)
points(data$Ozone, data$Wind,pch=15)
points(data$Ozone, data$Temp,pch=17)
```



##Adding points

- Be careful about the order in which you add points

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Wind,pch=16)
points(data$Ozone, data$Solar.R,pch=15)
points(data$Ozone, data$Temp,pch=17)
```

##Adding points

- Can define suitable axis limits in initial plot

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Wind,pch=16,ylim=c(0,350))
points(data$Ozone, data$Solar.R,pch=15)
points(data$Ozone, data$Temp,pch=17)
```




## Adding a legend

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Wind,pch=16,ylim=c(0,350))
points(data$Ozone, data$Solar.R,pch=15)
points(data$Ozone, data$Temp,pch=17)
legend("topright", legend=c("Solar","Wind","Temp"), 
       col="black", pch=c(16,15,17))
```

##Adding text

```{r fig.height=4,fig.width=8}
mycols <- rep("black", 153)
mycols[c(117,62,99,121,30)] <- "red"

plot(data[,1], pch=16, col=mycols)
text(c(117,62,99,121,30), data[c(117,62,99,121,30),1], 
     labels=LETTERS[1:5])
```

##Adding lines

```{r fig.height=4,fig.width=8}
mycols <- rep("black", 153)
mycols[c(117,62,99,121,30)] <- "red"

plot(data[,1], pch=16, col=mycols)
abline(h = 115)

```



##Adding lines

```{r fig.height=4,fig.width=8}

plot(data[,1], pch=16, col=mycols)
grid(col="steelblue")
```

##Adding lines

- `abline` can take a gradient and intercept argument
- for `y = x` use `a=0` and `b=1`
- Can be used to draw a *line of best fit* in conjunction with a linear model

```{r fig.height=4,fig.width=8}
plot(1:10, jitter(1:10))
abline(0,1)
```


# 2. Statistics
##Built-in support for statistics
- R is a statistical programming language
    + Classical statistical tests are built-in
    + Statistical modeling functions are built-in
    + Regression analysis is fully supported
    + Additional mathematical packages are available (`MASS`, Waves, sparse matrices, etc)
  
##Distribution functions  
- Most commonly used distributions are built-in, functions have stereotypical names, e.g. for normal distribution
    + `pnorm` - cumulative distribution for x
    + `qnorm` - inverse of pnorm (from probability gives x)
    + `dnorm` - distribution density
    + `rnorm` - random number from normal distribution
  
![distributions](images/distributions.png)  
  
- available for variety of distributions: `punif` (uniform), `pbinom` (binomial), `pnbinom` (negative binomial), `ppois` (poisson), `pgeom` (geometric), `phyper` (hyper-geometric), `pt` (T distribution), pf (F distribution) 

##Distribution functions 
- 10 random values from the Normal distribution with mean 10 and standard deviation 5
```{r eval=FALSE}
rnorm(10, mean=10, sd=5)
```
- The probability of drawing 10 from this distribution
```{r}
dnorm(10, mean=10, sd=5)
```

```{r}
dnorm(100, mean=10, sd=5)
```
- The probability of drawing a value smaller than 10
```{r}
pnorm(10, mean=10, sd=5)
```
- The inverse of `pnorm`
```{r}
qnorm(0.5, mean=10, sd=5)
```
- How many standard deviations for statistical significance?
```{r}
qnorm(0.95, mean=0, sd=1)
```

##Two sample tests: Basic data analysis

- Comparing 2 variances
    + Fisher's F test
```{r eval=FALSE}
var.test()
```
- Comparing 2 sample means with normal errors
    + Student's t test
```{r eval=FALSE}
t.test()
```
- Comparing 2 means with non-normal errors
    + Wilcoxon's rank test
```{r eval=FALSE}
wilcox.test()
```

##Two sample tests: Basic data analysis
- Comparing 2 proportions
    + Binomial test
```{r eval=FALSE}
prop.test()
```
- Correlating 2 variables
    + Pearson's / Spearman's rank correlation
```{r eval=FALSE}
cor.test()
```
- Testing for independence of 2 variables in a contingency table
    + Chi-squared / Fisher's exact test
```{r eval=FALSE}
chisq.test();fisher.test()
```


##Comparison of 2 data sets example: Basic data analysis

- Men, on average, are taller than women.
- The steps involved in test such a claim;
  1. Determine whether variances in each data series are different. 
    + Variance is a measure of sampling dispersion, a first estimate in determining the degree of difference
        + e.g. Fishers' F test
  2. Comparison of the mean heights. e.g. Student's t test, Wilcoxon's rank sum test
    + Determine probability that mean heights are really drawn from different sample populations
        + e.g. Student's t-test, Wilcoxon's rank sum test
  
##Comparison of 2 data sets example: Fisher's F test

- Read in the data file into a new object, `heightData`
```{r eval=FALSE}
heightData <- read.csv("1.5_heightData.csv")
```
- **attach** the data frame so we don't have to refer to it by name all the time
```{r eval=FALSE}
attach(heightData)
```
- Do the two sexes have the same variance?
```{r eval=FALSE}
var.test(Female,Male)
```

```{r echo=FALSE}
options(width=40)
setwd("Day_2_scripts/")
heightData <- read.csv("1.5_heightData.csv")
attach(heightData)
var.test(Female,Male)
```

##Comparison of 2 data sets example: Student's t test
- Student's t test is appropriate for comparing the difference in mean height in our data. 
      + We need a one-tailed test
      + Choose value of `var.equal` argument based on results of previous slide
```{r}
t.test(Female, Male, alternative="less",var.equal=TRUE)
```

##Comparison of 2 data sets example: Review findings

```{r}
boxplot(heightData)
```

##Linear regression: Basic data analysis

- Linear modeling is supported by the function `lm()`
    + `example(lm)` the output assumes you know a fair bit about the subject

- `lm` is really useful for plotting lines of best fit to XY data in order to determine intercept, gradient & Pearson's correlation coefficient
    + This is very easy in R

- Three steps to plotting with a best fit line
  1. Plot XY scatter-plot data
  2. Fit a linear model
  3. Add bestfit line data to plot with `abline()` function
  
##Typical linear regression analysis: Basic data analysis

 
```{r fig.height=4}
x <- c(1, 2.3, 3.1, 4.8, 5.6, 6.3)
y <- c(2.6, 2.8, 3.1, 4.7, 5.1, 5.3)
plot(y~x, xlim=c(0,10), ylim=c(0,10))
```

* The ~ is used to define a formula; i.e. "y is given by x"*

##Typical linear regression analysis: Basic data analysis

* The ~ is used to define a formula; i.e. "y is given by x"*
```{r}
plot(y~x, xlim=c(0,10), ylim=c(0,10))
myModel <- lm(y~x)
abline(myModel)
```

##Typical linear regression analysis: Basic data analysis
- Get the coefficients of the fit from:
```{r eval=FALSE}
summary.lm(myModel)
coef(myModel)
resid(myModel)
fitted(myModel)
```
- Get QC of fit from
```{r eval=FALSE}
plot(myModel)
```
- Find out about the fit data from
```{r eval=FALSE}
names(myModel)
```

##Modelling formulae
- R has a very powerful formula syntax for describing statistical models
- Suppose we had two explanatory variables `x` and `z` and one response
variable `y`
- We can describe a relationship between, say, `y` and `x` using a tilde `~`,
placing the response variable on the left of the tilde and the explanatory variables on the right:
    + `y~x`
- It is very easy to extend this syntax to do multiple regressions, ANOVAs, to include interactions, and to do many other common modelling tasks. For example
```{r eval=FALSE}
y~x       #If x is continuous this is linear regression
y~x       #If x is categorical, this is ANOVA
y~x+z     #If x and z are continuous, this is multiple regression
y~x+z     #If x and z are categorical, this is two-way ANOVA
y~x+z+x:z # : is the symbol for the interaction term
y~x*z     # * is a shorthand for x+z+x:z
```

##The linear model object. Basic data analysis
- Summary data describing the linear fit is given by
```{r}
summary(myModel)
```


##Exercise: The coin toss

To learn how the distribution functions work, try simulating tossing a fair coin 100 times and then show that it is fair

- We can model a coin toss using the binomial distribution. Use the `rbinom` function to generate a sample of 100 coin tosses. Look up the binomial distribution help page to find out what arguments this function needs
- How many heads or tails were there in your sample? You can do this in two ways; either select the number of successes using indices, or convert your sample to a factor and get a summary of the factor
- If we toss a coin 50 times, what is the probability that we get exactly 25 heads? What about 25 heads or less? Use `dbinom` and `pbinom` to find out
- The argument to `dbinom` is a vector, so try calculating the probabilities for getting any number of coin tosses from 0 to 50 in fifty trials using `dbinom`. Plot these probabilities using `plot`. Does this plot remind you of anything?

##Coin toss answers
- To simulate a coin toss, give `rbinom` a number of observations, the number of trials for each observation, and a probability of success

```{r}
coin.toss <- rbinom(100, 1, 0.5)
```
- Because we only specified one trial per observation, we either have an outcome of 0 or 1 successes. To get the number of successes, use indices or a factor to look up the number of 1s in the coin.toss vector (your numbers will vary)
```{r}
length(coin.toss[coin.toss==1])
summary(factor(coin.toss))
```

##Coin toss answers
- The probability of getting exactly 25 heads from 50 observations of a fair coin
```{r eval=FALSE}
dbinom(25, 50, 0.5)
```
- The probability of getting 25 heads or less from 50 observations of a fair coin
```{r eval=FALSE}
pbinom(25, 50, 0.5)
```
- The probabilities for getting all numbers of coin tosses from 0 to 50 in fifty trials
```{r eval=FALSE}
dbinom(0:50, 50, 0.5)
```
- To plot this distribution, which should resemble a normal distribution
```{r eval=FALSE}
plot(dbinom(0:50, 50, 0.5))
```

##Exercise: Linear modelling example
Mice have varying numbers of babies in each litter. Does the size of the litter affect the average brain weight of the offspring? We can use linear modelling to find out. (This example is taken from John Maindonald and John Braun's book Data Analysis and Graphics Using R (CUP, 2003), p140-143.)

- Install and load the `DAAG` package. The `litters` data frame is part of this package. Take a look at it. How many variables and observations does it have? Does `summary` tell you anything useful? What about `plot`?
- Are any of the variables correlated? Look up the `cor.test` function and use it to test for relationships.
- Use `lm` to calculate the regression of brain weight on litter size, brain weight on body weight, and brain weight on litter size and body weight together
- Look at the coefficients in your models. How is brain weight related to litter size on its own? What about in the multiple regression? How would you interpret this result?

##Linear modelling answers

- To install and load the package and look at `litters`

```{r echo=FALSE,message=FALSE,warning=FALSE,include=FALSE}
if(!require(DAAG)) install.packages("DAAG",repos = c("CRAN" = "http://cran.ma.imperial.ac.uk"))
```

```{r eval=FALSE}
install.packages("DAAG")
```

```{r eval=FALSE}
library(DAAG)
litters
summary(litters)
plot(litters)
```
- To calculate the correlations between variables
```{r eval=FALSE}
attach(litters)
cor.test(brainwt,lsize)
cor.test(bodywt,lsize)
cor.test(brainwt,bodywt)
```


##Linear modelling answers

```{r echo=FALSE}
library(DAAG)
attach(litters)
```

- To calculate the linear models
```{r}
lm(brainwt~lsize)
lm(brainwt~bodywt)
lm(brainwt~lsize+bodywt)
```

- *Interpretation*: brain weight decreases as litter size increases, but brain weight increases proportional to body weight (when bodywt is held constant, the lsize coefficient is positive: 0.00669). This is called 'brain sparing'; although the offspring get smaller as litter size increases, the brain does not shrink as much as the body

%##Basic R 'Built-in' functions for working with data frames

%- We have seen before how we can get the names of our variables, but for data frames and matrices we can also get these names with `colnames`, and the %names of the rows with `rownames`

%```{r programming5}
%names(patients)
%colnames(patients)
%rownames(patients)
%```

%##Basic R 'Built-in' functions for working with data frames
%- We can get the numbers of rows or columns with `nrow` and `ncol`

%```{r programming6}
%nrow(patients)
%ncol(patients)
%dim(patients)
%```

%##Basic R 'Built-in' functions for working with data frames

%- We can also find the length of a vector or a list with `length`, although this may give confusing results for some structures, like data frames:

%```{r programming7}
%length(c(1,2,3,4,5))
%length(patients)
%length(patients$Age)

%```

%*Remember, a data frame is a list of variables, so its length is the number of variables. The length of one of the variable vectors (like Age) is the %number of observations*

%##Basic R 'Built-in' functions for working with data frames

%- We can add rows or columns to a data frame using rbind and cbind
%```{r echo=FALSE}
%options(width=80)
%```

%```{r data-frames1}
%newpatient <- c("Kate", "Lawson", "Kate Lawson", "Female", "35", "62.5","TRUE")
%rbind(patients,newpatient)
%```
%- Note we are not altering the `patients` data frame, just displaying to the screen
%    + we would have to use an assignment `<-` operator to create a new object
    
%##Basic R 'Built-in' functions for working with data frames

%```{r data-frames2}
%cbind(patients,10:1)
%```
%- Note we are not altering the `patients` data frame, just displaying to the screen
%    + we would have to use an assignment `<-` operator to create a new object

%##Basic R 'Built-in' functions for working with data frames

%- We can also remove rows and columns
%%```{r}
%patients[-1, ] # remove first row
%```

%##Basic R 'Built-in' functions for working with data frames

%- We can also remove rows and columns%
%```{r}
%patients[ ,-1] # remove first column
%```


%##Basic R 'Built-in' functions for working with data frames

%- Sorting a vector with `sort`

%```{r data-frames3}
%sort(patients$Second_Name)
%```

%- Sorting a data frame by one variable with `order`

%```{r data-frames4}
%order(patients$Second_Name)
%patients[order(patients$Second_Name),]
%```

%##Exercise

%- Output the patients data frame, with the patients sorted in order of age, oldest first. (You may need the `rev` function, or look at the options for the %`order` function)
%- Add a `height` column to the data frame using the `cbind` function and assign the result to a new data frame
%    + enter your own height values, or use these 1.8, 1.6, 1.9, 1.5, 1.7, 1.5,1.75,1.8,1.6,1.5
%- Calculate the *body mass index* for each patient. Order the patients according to their bmi
%    + $bmi = \frac{weight}{height^2}$
%- A person is classified as overweight if they have a bmi > 25. Which patients are overweight using this criteria, and have consented to having their data %shared?

%##Answers
%- Make sure we have the correct patients data frame

%```{r include=FALSE}
%source("Day_1_scripts/1.2_patients.R")
%```

%```{r eval=FALSE}
%source("1.2_patients.R")
%```


%```{r}
%%patients[order(patients$Age,decreasing = TRUE),]
%```

%```{r}
%patients2 <- cbind(patients, Height = c(1.8, 1.6, 1.9, 1.5, 1.7, 1.5,1.75,1.8,1.6,1.5))
%patients2
%```

%##Answers

%```{r}
%%bmi <- patients2$Weight / (patients2$Height)^2
%bmi
%patients2[bmi > 25 & patients2$Consent,]
%```



# 3. Report Writing

##The R scripting language


* A script is a series of instructions that when executed sequentially automates a task
    + A script is a good solution to a repetitive problem
* The art of good script writing is
    + understanding exactly what you want to do
    + expressing the steps as concisely as possible
    + making use of error checking
    + including descriptive comments
* R is a powerful scripting language, and embodies aspects found in most standard programming environments
    + procedrual statements
    + loops
    + functions
    + conditional branching
* Scripts may be written in any standard text editor, e.g. notepad, gedit, kate
    + we will use RStudio

## Principles of Reproducible Research

![step-two](images/SidneyHarris_MiracleWeb.jpg)

Sidney Harris - New York Times

## Why should we do reproducible research?

Five selfish reasons - [Florian Markowetz Blog](https://scientificbsides.wordpress.com/2015/07/15/five-selfish-reasons-for-working-reproducibly/) and [slides](http://f1000research.com/slides/4-207)

1. Avoid disaster
2. Easier to write papers
3. Easier to talk to reviewers
4. Continuity of your work in the lab
5. Reputation


##It is a hot topic at the moment

- Statisticians at MD Anderson tried to reproduce results from a Duke paper and unintentionally unravelled a web of incompetence and skullduggery
    + as reported in the ***New York Times***
    
![nyt-article](images/rep-research-nyt.png)

##Hear the full account

- Very entertaining talk from Keith Baggerly in Cambridge 2010

<iframe width="560" height="315" src="https://www.youtube.com/embed/7gYIs7uYbMo" frameborder="0" allowfullscreen></iframe>


##What can we do about it?

- Use scripts / R
- Use version control
- Document early
- Document everything
- Write comments and explanations
- Automatically-generate your plots, tables, etc from the data
    + always ensure that you have the latest version

##Simple example in RStudio
- Lets take Day_1_scripts/1.3_NBcountData.R
    + an analysis of a RNA-seq dataset using edgeR
- Use the Compile Notebook button in RStudio
- Take an R script and turn into HTML, PDF or even Word
- All code will be displayed and the outputs printed
- A compiled report will be generated in your working directory

![compile](images/RStudio-menu.png)



## What is going on?

- The `knitr` package is being used convert the R script into 'markdown' format, which it then compiles into the output of your choosing
- `knitr` is distributed with RStudio
    + `knitr` is the modern-day equivalent of `Sweave`
- markdown is a easy-to-read, easy-to-write text format often used to write HTML, readme files etc
- the following should create the file `rna-seq.Rmd` in your working directory

```{r eval=FALSE}
library(knitr)
spin(hair="Day_1_scripts/1.3_NBcountData.R",knit=FALSE)
```

## Not quite enough for a reproducible document

- Minimally, you should record what version of R, and the packages you used.
- use the `sessionInfo()` function
    + e.g. for the version of R I used to make the slides
```{r}
sessionInfo()
```

- Lets add this to the R scripts and see what happens


## Defining chunks

- It is not great practice to have one long, continuous R script
- Better to break-up into smaller pieces; '*chunks*'
- You can document each chunk separately
- Easier to catch errors
- The characteristics of each chunk can be modified
    + You might not want to print the R code for each chunk
    + or the output
    + etc

## Create a markdown file from scratch

File - > New File - > R Markdown

- Choose 'Document' and the default output type (HTML)
- A new tab is created in RStudio
- The header also you to specify a Page title, author and output type
```{r eval=FALSE}
---
title: "Untitled"
author: "Mark Dunning"
date: "16/06/2015"
output: html_document
---
```

## Format of the file

- **Lines 8 - 10** Plain text description
- **Lines 12 - 14** An R code 'chunk'
- **Lines 18 to 20** Another code chunk, this time producing a plot

![md-format](images/markdown-format.png)

- Pressing the ***Knit HTML*** button will create the report
    + Note that you need to 'save' the markdown file before you will see the compiled report in your working directory
    
##Text formatting
See ***Markdown Quick Reference*** in RStudio

- enclose text in \* to format in *italics*
- enclose text in \*\* to format in **bold**
- \*\*\* for ***bold italics***
- \` to format like `code`
- \$ to include equations: $e =mc^2$
- \> quoted text: 

>To be or not to be

- see Markdown Quick Reference for more 
    + adding images
    + adding web links
    + tables

## Chunk options

- It's a good idea to name each chunk
    + Easier to track-down errors
- We can display R code, but not run it
    + `eval=FALSE`
- We can run R code, but not display it
    + `echo=FALSE`
    + e.g. setting display options
- Suppress warning messages
    + `warning=FALSE`

    
## Chunk options: eval

- Sometimes we want to format code for display, but not execute
    + we want to show the code for how we read our data, but want our report to compile quickly

```
'''{r,eval=FALSE}
data <- read.delim("path.to.my.file")
'''
```


## Chunk options: echo

- might want to load some data from disk
    + e.g. the R object from reading the data in the previous slide
- your P.I. wants to see your results, but doesn't really want to know about the R code that you used
```
'''{r echo=FALSE}
load("mydata.rda")
'''
```

## Chunk options: results

- Some code or functions might produce lots of output to the screen that we don't need
```{r results='hide'}
for(i in 1:100){
  print(i)
}
```

##Chunk options: message and warning

- Loading an R package will sometimes print messages and / or warnings to the screen
    + not always helpful in a report
```
'''{r}
library(DESeq)
'''
```

```{r echo=FALSE}
library(DESeq)
```

##Chunk options: message and warning

- Using `message=FALSE` and `warning=FALSE`
```
'''{r message=FALSE,warning=FALSE}
library(DESeq)
'''
```
- Could also need `suppressPackageStartupMessages`

##Chunk options: cache

- `cache=TRUE` will stop certain chunks from being evaluate if their code does not change
- speeds-up the compilation of the document
    + we don't want to reload our dataset if we've only made a tiny change downstream
```
'''{r echo=FALSE,cache=TRUE}
load("mydata.rda")
'''
```

## Including plots

- Use a plotting function (`plot`, `boxplot`, `hist` etc) will include the plot at the relevant point in the document
```
'''{r}
plot(1:10, jitter(1:10))
'''
```

```{r echo=FALSE}
plot(1:10, runif(10))
```

## Control over plots

```
'''{r fig.height=2,fig.align='right', fig.height=4,fig.width=9}
plot(1:10, jitter(1:10))
'''
```

```{r echo=FALSE,fig.height=3,fig.align='right', fig.height=4,fig.width=9}
plot(1:10, runif(10))
```


## Running R code from the main text

- We can add R code to our main text, which gets evaluated
    + make sure we always have the latest figures, p-values etc

```
.....the sample population consisted of  'r table(gender)[1]' females and 'r table(gender)[2]' males.....
```

```{r echo=FALSE}
gender <- c(rep("F", 47), rep("M", 50))
```
.....the sample population consisted of  `r table(gender)[1]` females and `r table(gender)[2]` males.....



```
.....the p-value of the t-test is 'r pval', which indicates that.....
```
```{r echo=FALSE}
pval <- 0.05
```
.....the p-value of the t-test is `r pval`, which indicates that.....

## Running R code from the main text

- Like the rest of our report these R statements will get updated each time we compile the report

```
.....the sample population consisted of  'r table(gender)[1]' females and 'r table(gender)[2]' males.....
```

```{r echo=FALSE}
gender <- c(rep("F", 41), rep("M", 54))
```
.....the sample population consisted of  `r table(gender)[1]` females and `r table(gender)[2]` males.....



```
.....the p-value of the t-test is 'r pval', which indicates that.....
```
```{r echo=FALSE}
pval <- 0.1
```
.....the p-value of the t-test is `r pval`, which indicates that.....



## Conditional output

```{r}
pval <- 0.1
```


```
.....The statistical test was 'r ifelse(pval < 0.05, "", "not")' significant....
```



The statistical test was `r ifelse(pval < 0.05, "", "not")` significant

```{r}
pval <- 0.01
```


```
.....The statistical test was 'r ifelse(pval < 0.05, "", "not")' significant....
```


The statistical test was `r ifelse(pval < 0.05, "", "not")` significant


## Printing vectors
```
The months of the year are 'r month.name'
```

The months of the year are `r month.name`

## References

- Useful reference:
    +  Reproducible Research in R and RStudio
        + http://christophergandrud.github.io/RepResR-RStudio/
        + Useful exercise is to compile the book from the [source code](https://github.com/christophergandrud/Rep-Res-Book)
    + [Implementing Reproducible Research](https://osf.io/s9tya/wiki/home/)


## Exercise

- Create a new markdown file that will report your analysis of the NB count data
    + File -> New File -> R Markdown
- Create separate code chunks for each stage of the analysis (copy code from Day_1_scripts/1.3_NBcountData.R if you wish)
    + Reading the data
    + Basic Statistics
    + Reorder table by decreasing nuclei count
    + Identify patients with >33% NB amplification
    + Write out results table as comma separated values file
    
## Exercise

- Once you have a report that you are happy with
- Use in-line R code to report how many patients have > 33% amplifications
- A new dataset is acquired with 100 observations, futhermore we now want to identify patients with 30% amplifications
    + 'updated-NBcountData.txt'
- Modify your report so that it can read the new data and use the new criteria


# 4. Programming Techniques

##Introducing loops

- Many programming languages have ways of doing the same thing many times, perhaps changing some variable each time. This is called *looping*
- Loops are not used in R so often, because we can usually achieve the same thing using vector calculations
- For example, to add two vectors together, we do not need to add each pair of elements one by one, we can just add the vectors
```{r eval=FALSE}
x<- 1:10
y <- 11:20
x+y
```
- But there are some situations where R functions can not take vectors as input. For example, `read.csv` will only load one file at a time
- What if we had ten files to load in, all ending in the same extension (like `.csv`)?

##Introducing loops
- We could do this:

```{r eval=FALSE}
colony  <-data.frame() # Start with empty data frame
colony1 <- read.csv("11_CFA_Run1Counts.csv")
colony2 <- read.csv("11_CFA_Run2Counts.csv")
colony3 <- read.csv("11_CFA_Run3Counts.csv")
  ...
colony10 <- read.csv("11_CFA_Run10Counts.csv")
colony <- rbind(colony1, colony2, colony3, ..., colony10)
```
- But this will be boring to type, difficult to change, and prone to error
- As we are doing the same thing 10 times, but with a different file name each time, we can use a **loop** instead

##Loops: Commands and flow control
- R has two basic types of loop
    + a `for` loop: run some code on every value in a vector
    + a `while` loop: run some code while some condition is true
    
`for` 
```{r loops1, eval=FALSE}
for(i in 1:10){
  print(i)
}
```
`while`
```{r  eval=FALSE}
i <- 1
while ( i <= 10 ) {
   print(i)
   i <- i + 1
}
```

##Loops: Commands and flow control

- Here's how we might use a `for` loop to load in our CSV files
- If the data files are in your current working directory, we can look up files
containing a particular substring in their name using the `dir` function



```{r eval=FALSE}
dir(pattern="Counts.csv")
```

```{r echo=FALSE}
dir("Day_1_scripts/",pattern="Counts.csv")

```

- So we can load all the files using a `for` loop as follows

```{r loops2, eval=FALSE}
colony <- data.frame()
countfiles <- dir(pattern="Counts.csv")
for (file in countfiles) {
   t <- read.csv(file)
   colony <- rbind(colony, t)
}
```

- Here, we use a temporary variable `t` to store the data in each file, and then add that data to the main `colony` data frame.

##Conditional branching: Commands and flow control

- Use an `if` statement for any kind of condition testing
- Different outcomes can be selected based on a condition within brackets

```{r if, eval=FALSE}
if (condition) {
... do this ...
} else {
... do something else ...
}

```

- `condition` is any logical value, and can contain multiple conditions. 
    + e.g. `(a == 2 & b < 5)`, this is a compound conditional argument

##Conditional branching: Commands and flow control
- For example, if we were writing a script to load an unknown set of files, using the `for` loop we wrote before, we might want to warn the user if we can't find any files with the pattern we are searching for. Here's how we can use an `if` statement to test for this

```{r flow-control,eval=FALSE}
colony <- data.frame()
countfiles <- dir(pattern="Counts.csv")
if (length(countfiles) == 0) {
    stop("No Counts.csv files found!")
} else {
    for (file in countfiles) {
        t <- read.csv(file)
        colony <- rbind(colony, t)
    }
}

```

- The `stop` function outputs the error message and quits


##Code formatting avoids bugs!
Compare:
```{r eval=FALSE}
f -26
while(f!=0){
print(letters[f])
f <- f-1}
```
to:
```{r eval=FALSE}
f <- 26
while( f != 0 ){
   print(letters[f])
   f <- f-1
}
```
- The code between brackets `{}` *always* is *indented*, this clearly separates what is executed once, and what is run multiple times
- Trailing bracket `}` always alone on the line at the same indentation level as the initial bracket `{`
- Use white spaces to divide the horizontal space between units of your code, e.g. around assignments, comparisons

##Exercise


- Load in the `colony` data frame using a `for` loop. Three of the data files are in the `Day_1_scripts` folder. Load all three files into `colony` using the for loop in the slides
- How many observations do you have in the colony data frame? Find out by counting the number of rows in `colony` using the `nrow` function
- Suppose a power analysis of your data shows that you only need 48 observations to robustly test your hypothesis. This means we can stop loading files when we have loaded at least 48 observations. Modify your `for` loop so it will only load files if the `colony` data frame has less than 48 observations in it

##Answers to Exercise

- To order the patients by decreasing age
```{r ex3ans1,eval=FALSE}
patients[rev(order(patients$Age)),]
```
- To find the number of rows in the colony data frame
```{r ex3ans2,eval=FALSE}
nrow(colony)
```

- To stop loading files after at least 48 observations have been found, use the code from the first `for` loop slide with a new `if` statement

```{r ex3ans4, eval=FALSE}
colony <- data.frame()
countfiles <- dir(pattern="Counts.csv")
for (file in countfiles) {
    if (nrow(colony) < 48 ) {
        t <- read.csv(file)
        colony <- rbind(colony, t)
    }
}
```



# 5. Data analysis report example

## Combining data from multiple sources: *Gene Clustering Example*

* R has powerful functions to combine heterogeneous data into a single data set
* Gene clustering example data
    + five sets of differentially expressed genes from various experimental conditions
    + file with names of experimentally-verified genes
* Gene clustering exercise
    + combine this dataset into a single table and cluster to see which conditions are similar
    + repeat the clustering but only on a subset of experimentally-verified genes
    
## Combining gene tables

* input files have two columns: gene names and fold change
* we want to combine all five tables into a single table, with 0 for missing values
![gene-tables](images/gene-tables.png)

## Gene Clustering: Script Walkthrough 1

* To make the big table we first need to find out all the genes present in at least one of the files
* Make sure not to use factors in `read.delim()`
    + when loading in character data, use `as.is=TRUE` to prevent it being converted to factors
    + `union()` is a set operation which combines two vectors by eliminating duplicates. See also `intersect` and `setdiff`

```{r eval=FALSE}
#start with an empty collection of genes
genes <- c()
for(fileNum in 1:5){
  #load in files 2_3.DiffGenes1.tsv...
  t <- read.delim(paste("2.3_DiffGenes", fileNum, ".tsv"
                        , sep="")
                  , as.is=TRUE, header=FALSE)
  #label the input columns to help code readability
  names(t) <- c("gene", "expression")
  genes <- union(genes, t$gene)
}
#for tidiness order our genes by name
genes <- sort(genes)
genes #show all genes
```
- *Example code: 2.3_geneClustering.R*

## Gene Clustering: Script Walkthrough 2

* Using the complete list of genes, we can create the big table and fill in the values:
    + `match()` returns the index of the first argument in the second. i.e. index of input file genes in the big table
    + we use index to pick the rows in such way that they match the order in the input file
    
```{r eval=FALSE}
#make the destination table [rows=unique genes,cols=file numbers]
values <- matrix(0, nrow=length(genes), ncol=5)
rownames(values) <- genes
for(fileNum in 1:5){
  #read in the file again
    t <- read.delim(paste("2.3_DiffGenes", fileNum,".tsv"
                        , sep=""), as.is=TRUE, header=FALSE)
    names(t) <- c("gene","expression")
    index <- match(t$gene, rownames(values))
    values[index,fileNum] <- t$expression
}
```

## Gene Clustering: Script Walkthrough 3

* Now we can do hierarchical clustering:
    + Values from the matrix are colour-coded. Rows and columns are re-arranged according to similarity

```{r eval=FALSE,fig.height=4}
heatmap(values, scale="none", col=cm.colors(256))
```

```{r echo=FALSE}
setwd("Day_2_scripts/")
genes <- c()
for(fileNum in 1:5){
  t <- read.delim(paste("2.3_DiffGenes", fileNum, ".tsv"
                        , sep="")
                  , as.is=TRUE, header=FALSE)
  names(t) <- c("gene", "expression")
  genes <- union(genes, t$gene)
}
genes <- sort(genes)
values <- matrix(0, nrow=length(genes), ncol=5)
rownames(values) <- genes
for(fileNum in 1:5){
    t <- read.delim(paste("2.3_DiffGenes", fileNum, ".tsv"
                        , sep=""), as.is=TRUE, header=FALSE)
    names(t) <- c("gene", "expression")
    index <- match(t$gene, rownames(values))
    values[index, fileNum] <- t$expression
}
heatmap(values, scale="none", col=cm.colors(256))

```

## Gene Clustering: Script Walkthrough 4 

* In a second part of our analysis, we want to produce the same heatmap but only based on a list of experimentally-verified genes
* The problem is that the data are not formatted in the most convenient way:

![gene-lists](images/gene-lists.png)


## Gene Clustering: Script Walkthrough 5

* We load in this table, and only extract the gene names, then we use them to select a subset of the `values` matrix
```{r eval=FALSE}
t.exp <- read.delim("2.3_ExperimentalGenes.tsv",
                    as.is=TRUE)
experim.genes <- unlist(strsplit(t.exp$genes, ","))
```
* `unlist` flattens out a nested list into a single vector
* `strsplit` splits a vector of strings by a custom split character (`,`). The result is a list of split values for each element of the input vector
* Now, redo the heatmap by using just the genes in the experimentally verified set  
```{r eval=FALSE}
is.experimental <- rownames(values) %in% experim.genes
heatmap(values[is.experimental,], scale="none"
        , col=cm.colors(256))
```

## Gene Clustering Review

* We load the five tables twice; first to collect gene names, then to load expression values
* Based on the expression table (`values`) we construct a clustered heatmap first on the whole set of genes, then on a selected subset
* Go through the code, try it out and understand it
* Try answering the following questions
    + what is `rownames(values)`
    + why is `rownames(values)[index]` and `t$gene` giving the same output?
    + what is the difference between `rownames(values) %in% experim.genes` and `experim.genes %in% rownames(values)`
  

#References

##References
* Official documentation on:
    + http://cran.r-project.org/manuals.html
* A good repository of R recipes
    + Quick-R: http://www.statmethods.net/
* Don't forget that many packages come with tutorials (vignettes)
* R forums
    + http://stackoverflow.com/questions/tagged/r
    + http://news.gmane.org/gmane.comp.lang.r.general
    
* Plenty of textbooks to choose from, comprehensive list + reviews
    + http://www.r-project.org/doc/bib/R-books.html

#End of Course

##Thanks for your attention

- Please fill-in your feedback so we can improve the course
- The key to learning R is practice, practice, practice!
    + If you don't have your own data yet, look online
    + http://vincentarelbundock.github.io/Rdatasets/datasets.html
- Meet with fellow R users
    + http://www.meetup.com/Cambridge-R-Users-Group-Meetup/
    + informal, quarterly talks
- Look out for an 'Intermediate R' course    

    
