---
title: "Introduction to Solving Biological Problems Using R - Day 2"
author: Mark Dunning and Aiora Zabala. Original material by Robert Stojnić, Laurent Gatto, Rob Foy
  John Davey, Dávid Molnár and Ian Roberts
date: '`r format(Sys.time(), "Last modified: %d %b %Y")`'
output: slidy_presentation
toc: yes
---

## Day 2 Schedule

1. Further customisation of plots
2. Statistics
3. Report-writing
4. Programming Techniques
5. Data analysis report

#1. Further customisation of plots

## Recap

- we have seen how to use `plot`, `boxplot` `hist` to make simple plots
- these come with arguments that can be used to change the appearance of the plot
    + `col`, `pch`
    + `main`, `xlab`, `ylab`
    + etc....
- we will now look at ways to modify the plot appearance after it has been created

## The painter's model

- R employs a painter's model to construct it's plots


##Initial plot

```{r}
data <- read.csv("Day_1_scripts/ozone.csv")
plot(data$Ozone, data$Solar.R,pch=16)
```

##The points function

- `points` can be used to set of points to an *existing* plot
- it requires a vector of x and y coordinates
- Note that axis limits of the existing plot are not altered

##Adding points

```{r}
data <- read.csv("Day_1_scripts/ozone.csv")
plot(data$Ozone, data$Solar.R,pch=16)
points(data$Ozone, data$Wind)
```

##Adding points

`points` can also use the `pch`, `col` arguments. Useful for distinguishing between variables

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Solar.R,pch=16)
points(data$Ozone, data$Wind,pch=15,col="red")
```


##Adding points

- Each set of points can have a different colour and shape
- Axis labels and title and limits are defined by the plot
- You can add points ad-nauseum. Try not to make the plot cluttered!
- A call to `plot` will start a new graphics window

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Solar.R,pch=16)
points(data$Ozone, data$Wind,pch=15)
points(data$Ozone, data$Temp,pch=17)
```



##Adding points

- Be careful about the order in which you add points

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Wind,pch=16)
points(data$Ozone, data$Solar.R,pch=15)
points(data$Ozone, data$Temp,pch=17)
```

##Adding points

- Can define suitable axis limits in initial plot

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Wind,pch=16,ylim=c(0,350))
points(data$Ozone, data$Solar.R,pch=15)
points(data$Ozone, data$Temp,pch=17)
```




## Adding a legend

```{r fig.height=4,fig.width=8}
plot(data$Ozone, data$Wind,pch=16,ylim=c(0,350))
points(data$Ozone, data$Solar.R,pch=15)
points(data$Ozone, data$Temp,pch=17)
legend("topright", legend=c("Solar","Wind","Temp"), 
       col="black", pch=c(16,15,17))
```

##Adding text

```{r fig.height=4,fig.width=8}
mycols <- rep("black", 153)
mycols[c(117,62,99,121,30)] <- "red"

plot(data[,1], pch=16, col=mycols)
text(c(117,62,99,121,30), data[c(117,62,99,121,30),1], 
     labels=LETTERS[1:5])
```

##Adding lines

```{r fig.height=4,fig.width=8}
mycols <- rep("black", 153)
mycols[c(117,62,99,121,30)] <- "red"

plot(data[,1], pch=16, col=mycols)
abline(h = 115)

```



##Adding lines

```{r fig.height=4,fig.width=8}

plot(data[,1], pch=16, col=mycols)
grid(col="steelblue")
```

##Adding lines

- `abline` can take a gradient and intercept argument
- for `y = x` use `a=0` and `b=1`
- Can be used to draw a *line of best fit* in conjunction with a linear model

```{r fig.height=4,fig.width=8}
plot(1:10, jitter(1:10))
abline(0,1)
```


# 2. Statistics
##Built-in support for statistics
- R is a statistical programming language
    + Classical statistical tests are built-in
    + Statistical modeling functions are built-in
    + Regression analysis is fully supported
    + Additional mathematical packages are available (`MASS`, Waves, sparse matrices, etc)
  
##Distribution functions  
- Most commonly used distributions are built-in, functions have stereotypical names, e.g. for normal distribution
    + `pnorm` - cumulative distribution for x
    + `qnorm` - inverse of pnorm (from probability gives x)
    + `dnorm` - distribution density
    + `rnorm` - random number from normal distribution
  
![distributions](images/distributions.png)  
  
- available for variety of distributions: `punif` (uniform), `pbinom` (binomial), `pnbinom` (negative binomial), `ppois` (poisson), `pgeom` (geometric), `phyper` (hyper-geometric), `pt` (T distribution), pf (F distribution) 

##Distribution functions 
- 10 random values from the Normal distribution with mean 10 and standard deviation 5
```{r eval=FALSE}
rnorm(10, mean=10, sd=5)
```
- The probability of drawing 10 from this distribution
```{r}
dnorm(10, mean=10, sd=5)
```

```{r}
dnorm(100, mean=10, sd=5)
```
- The probability of drawing a value smaller than 10
```{r}
pnorm(10, mean=10, sd=5)
```
- The inverse of `pnorm`
```{r}
qnorm(0.5, mean=10, sd=5)
```
- How many standard deviations for statistical significance?
```{r}
qnorm(0.95, mean=0, sd=1)
```

##Two sample tests: Basic data analysis

- Comparing 2 variances
    + Fisher's F test
```{r eval=FALSE}
var.test()
```
- Comparing 2 sample means with normal errors
    + Student's t test
```{r eval=FALSE}
t.test()
```
- Comparing 2 means with non-normal errors
    + Wilcoxon's rank test
```{r eval=FALSE}
wilcox.test()
```

##Two sample tests: Basic data analysis
- Comparing 2 proportions
    + Binomial test
```{r eval=FALSE}
prop.test()
```
- Correlating 2 variables
    + Pearson's / Spearman's rank correlation
```{r eval=FALSE}
cor.test()
```
- Testing for independence of 2 variables in a contingency table
    + Chi-squared / Fisher's exact test
```{r eval=FALSE}
chisq.test();fisher.test()
```


##Comparison of 2 data sets example: Basic data analysis

- Men, on average, are taller than women.
- The steps involved in test such a claim;
  1. Determine whether variances in each data series are different. 
    + Variance is a measure of sampling dispersion, a first estimate in determining the degree of difference
        + e.g. Fishers' F test
  2. Comparison of the mean heights. e.g. Student's t test, Wilcoxon's rank sum test
    + Determine probability that mean heights are really drawn from different sample populations
        + e.g. Student's t-test, Wilcoxon's rank sum test
  
##Comparison of 2 data sets example: Fisher's F test

- Read in the data file into a new object, `heightData`
```{r eval=FALSE}
heightData <- read.csv("1.5_heightData.csv")
```
- **attach** the data frame so we don't have to refer to it by name all the time
```{r eval=FALSE}
attach(heightData)
```
- Do the two sexes have the same variance?
```{r eval=FALSE}
var.test(Female,Male)
```

```{r echo=FALSE}
options(width=40)
setwd("Day_2_scripts/")
heightData <- read.csv("1.5_heightData.csv")
attach(heightData)
var.test(Female,Male)
```

##Comparison of 2 data sets example: Student's t test
- Student's t test is appropriate for comparing the difference in mean height in our data. 
      + We need a one-tailed test
      + Choose value of `var.equal` argument based on results of previous slide
```{r}
t.test(Female, Male, alternative="less",var.equal=TRUE)
```

##Comparison of 2 data sets example: Review findings

```{r}
boxplot(heightData)
```

##Linear regression: Basic data analysis

- Linear modeling is supported by the function `lm()`
    + `example(lm)` the output assumes you know a fair bit about the subject

- `lm` is really useful for plotting lines of best fit to XY data in order to determine intercept, gradient & Pearson's correlation coefficient
    + This is very easy in R

- Three steps to plotting with a best fit line
  1. Plot XY scatter-plot data
  2. Fit a linear model
  3. Add bestfit line data to plot with `abline()` function
  
##Typical linear regression analysis: Basic data analysis

 
```{r fig.height=4}
x <- c(1, 2.3, 3.1, 4.8, 5.6, 6.3)
y <- c(2.6, 2.8, 3.1, 4.7, 5.1, 5.3)
plot(y~x, xlim=c(0,10), ylim=c(0,10))
```

* The ~ is used to define a formula; i.e. "y is given by x"*

##Typical linear regression analysis: Basic data analysis

* The ~ is used to define a formula; i.e. "y is given by x"*
```{r}
plot(y~x, xlim=c(0,10), ylim=c(0,10))
myModel <- lm(y~x)
abline(myModel)
```

##Typical linear regression analysis: Basic data analysis
- Get the coefficients of the fit from:
```{r eval=FALSE}
summary.lm(myModel)
coef(myModel)
resid(myModel)
fitted(myModel)
```
- Get QC of fit from
```{r eval=FALSE}
plot(myModel)
```
- Find out about the fit data from
```{r eval=FALSE}
names(myModel)
```

##Modelling formulae
- R has a very powerful formula syntax for describing statistical models
- Suppose we had two explanatory variables `x` and `z` and one response
variable `y`
- We can describe a relationship between, say, `y` and `x` using a tilde `~`,
placing the response variable on the left of the tilde and the explanatory variables on the right:
    + `y~x`
- It is very easy to extend this syntax to do multiple regressions, ANOVAs, to include interactions, and to do many other common modelling tasks. For example
```{r eval=FALSE}
y~x       #If x is continuous this is linear regression
y~x       #If x is categorical, this is ANOVA
y~x+z     #If x and z are continuous, this is multiple regression
y~x+z     #If x and z are categorical, this is two-way ANOVA
y~x+z+x:z # : is the symbol for the interaction term
y~x*z     # * is a shorthand for x+z+x:z
```

##The linear model object. Basic data analysis
- Summary data describing the linear fit is given by
```{r}
summary(myModel)
```


##Exercise: The coin toss

To learn how the distribution functions work, try simulating tossing a fair coin 100 times and then show that it is fair

- We can model a coin toss using the binomial distribution. Use the `rbinom` function to generate a sample of 100 coin tosses. Look up the binomial distribution help page to find out what arguments this function needs
- How many heads or tails were there in your sample? You can do this in two ways; either select the number of successes using indices, or convert your sample to a factor and get a summary of the factor
- If we toss a coin 50 times, what is the probability that we get exactly 25 heads? What about 25 heads or less? Use `dbinom` and `pbinom` to find out
- The argument to `dbinom` is a vector, so try calculating the probabilities for getting any number of coin tosses from 0 to 50 in fifty trials using `dbinom`. Plot these probabilities using `plot`. Does this plot remind you of anything?

##Coin toss answers
- To simulate a coin toss, give `rbinom` a number of observations, the number of trials for each observation, and a probability of success

```{r}
coin.toss <- rbinom(100, 1, 0.5)
```
- Because we only specified one trial per observation, we either have an outcome of 0 or 1 successes. To get the number of successes, use indices or a factor to look up the number of 1s in the coin.toss vector (your numbers will vary)
```{r}
length(coin.toss[coin.toss==1])
summary(factor(coin.toss))
```

##Coin toss answers
- The probability of getting exactly 25 heads from 50 observations of a fair coin
```{r eval=FALSE}
dbinom(25, 50, 0.5)
```
- The probability of getting 25 heads or less from 50 observations of a fair coin
```{r eval=FALSE}
pbinom(25, 50, 0.5)
```
- The probabilities for getting all numbers of coin tosses from 0 to 50 in fifty trials
```{r eval=FALSE}
dbinom(0:50, 50, 0.5)
```
- To plot this distribution, which should resemble a normal distribution
```{r eval=FALSE}
plot(dbinom(0:50, 50, 0.5))
```

##Exercise: Linear modelling example
Mice have varying numbers of babies in each litter. Does the size of the litter affect the average brain weight of the offspring? We can use linear modelling to find out. (This example is taken from John Maindonald and John Braun's book Data Analysis and Graphics Using R (CUP, 2003), p140-143.)

- Install and load the `DAAG` package. The `litters` data frame is part of this package. Take a look at it. How many variables and observations does it have? Does `summary` tell you anything useful? What about `plot`?
- Are any of the variables correlated? Look up the `cor.test` function and use it to test for relationships.
- Use `lm` to calculate the regression of brain weight on litter size, brain weight on body weight, and brain weight on litter size and body weight together
- Look at the coefficients in your models. How is brain weight related to litter size on its own? What about in the multiple regression? How would you interpret this result?

##Linear modelling answers

- To install and load the package and look at `litters`

```{r echo=FALSE,message=FALSE,warning=FALSE,include=FALSE}
if(!require(DAAG)) install.packages("DAAG",repos = c("CRAN" = "http://cran.ma.imperial.ac.uk"))
```

```{r eval=FALSE}
install.packages("DAAG")
```

```{r eval=FALSE}
library(DAAG)
litters
summary(litters)
plot(litters)
```
- To calculate the correlations between variables
```{r eval=FALSE}
attach(litters)
cor.test(brainwt,lsize)
cor.test(bodywt,lsize)
cor.test(brainwt,bodywt)
```


##Linear modelling answers

```{r echo=FALSE}
library(DAAG)
attach(litters)
```

- To calculate the linear models
```{r}
lm(brainwt~lsize)
lm(brainwt~bodywt)
lm(brainwt~lsize+bodywt)
```

- *Interpretation*: brain weight decreases as litter size increases, but brain weight increases proportional to body weight (when bodywt is held constant, the lsize coefficient is positive: 0.00669). This is called 'brain sparing'; although the offspring get smaller as litter size increases, the brain does not shrink as much as the body


# 3. Report Writing

##The R scripting language


* A script is a series of instructions that when executed sequentially automates a task
    + A script is a good solution to a repetitive problem
* The art of good script writing is
    + understanding exactly what you want to do
    + expressing the steps as concisely as possible
    + making use of error checking
    + including descriptive comments
* R is a powerful scripting language, and embodies aspects found in most standard programming environments
    + procedrual statements
    + loops
    + functions
    + conditional branching
* Scripts may be written in any standard text editor, e.g. notepad, gedit, kate
    + we will use RStudio

##Colony forming experiment

* We have been asked y some collaborators to analyse some trial data to see if an experiment will work
* We are interested in the behaviour of a gene, X, which is involved  in a cell proliferation pathway
* This pathway causes cells to proliferate in the presence of a compound, Z
* Gene X turns the pathway off, reducing cell proliferation
* Our collaborators want to test what happens when we knock down X in the presence of Z
* To do this, they want to grow cell colonies in the presence of Z, with or without X, and count the number of colonies that result

##Initial Trial

* Our collaborators have sent us a first batch of test data, growing colonies in different concentrations of compound Z, and replicating each Z concentration three times
* Does increasing concentration of Z have an effect on colony growth?
* We want to do the following:
    + Load the data into R
    + Plot the data to inspect them
    + Calculate an Analysis of Variance to see if the growth is influenced by Z concentration
    + Calculate the mean growth for each level of Z concentration, to see the direction of change
    
##Initial trial exercise

* The trial data are in the file '2.1\_colony\_trial.csv'. Load this file into R using the command we learnt yesterday
* Plot the data using a formula, to see how Z affects colony Count. Recall how we did this earlier with linear modelling, with independant variable x and dependent variable y: 
```{r eval=FALSE}
plot(y~x)
```
* Calculate an analysis of variance for the data. The R function for ANOVA is `aov`, which works like `lm()` from earlier
```{r eval=FALSE}
summary(lm(y~x))
```
* There are four concentrations of Z, and each concentration has been replicated three times. What is the mean colony count for each concentration? See if you can figure out a way to calculate this with what we learnt yesterday. You will need to use logical indexing and you may want to use a loop

##Importing data

* Use `read.csv` to load the data

```{r eval=TRUE,echo=FALSE}
setwd("Day_2_scripts/")
colony <- read.csv("2.1_colony_trial.csv")
```


```{r eval=FALSE}
colony <- read.csv("2.1_colony_trial.csv")
```

```{r echo=FALSE}
colony
```


##Importing data

```{r echo=FALSE}
colony[1:4,]
```


* The data frame has three columns; Z, Replicate and Count. We want to know how Z affects the number of colonies (Count). To do this, we need to summarise the data over all replicates for each concentration of Z.
* We will attach the data frame to our workspace, so we can refer to the variables without referring to the data frame all the time

```{r}
attach(colony)
```
* (We will also `detach` colony from the workspace at the end of our script)

##Plotting

- We want to plot the colony growth in response to changing Z concentration.
- Z is the explanatory variable and Count is the response variable
- We don't want to plot replicates separately here, but get R to summarise each Z over all replicates
- We can call plot using the same *formula syntax* we learnt earlier

```{r fig.height=4}
plot(Count ~ Z)
```

##Plotting

* We can improve on this. Firstly, we want to order the Z categories. Z is a factor, so we need to supply new levels to this factor in the colony data frame

```{r fig.height=4}
Z  <- factor(Z, levels=c("None", "Low",
                         "Medium", "High"))
plot(Count ~ Z)
```

##Analysis of Variance

* We can use the same formula syntax to calculate an analysis of variance:

```{r}
colony.aov <- aov(Count~Z)
summary(colony.aov)
```

* This tells us what we can already see from the plot, that there is a highly significant relationship between Z concentration and colony growth
* We would like to investigate this relationship. For example, we might want to calculate the mean colony count for each concentration of Z.

##Calculating group means

* We can calculate a mean for a particular group like this:
```{r}
mean(colony[Z == "None",]$Count)
mean(colony[Z == "Low",]$Count)
mean(colony[Z == "Medium",]$Count)
mean(colony[Z == "High",]$Count)


```

##Calculating group means

* We could generalise this with a for loop:

```{r}
for (z in levels(Z)){
  print(mean(colony[Z==z,]$Count))
}
```
* But there is a better way

##The tapply function: a brief digression

* The `apply` family of functions allow us to group data by variable and calculate something for each group
* Assume we have the following data for heights of 5 males and females

```{r}
data <- data.frame(gender = c("M","M","F","F","F"),
                   height = c(6,6.1,5.8,6,5.95))
data
```
* How can we get the mean of males and females separately?
* The `tapply` function lets us do exactly this

```{r eval=FALSE}
tapply(data, groups, function)
```
* in our case:
```{r}
tapply(data$height, data$gender, mean)
```

##Using tapply on colony

* We can use tapply to calculate group means on colony like this:

```{r fig.height=4}
colony.means <- tapply(Count, Z, mean)
colony.means
barplot(colony.means)
```

##A complete script

* We now have a complete script to analyse these data
```{r eval=FALSE}
#Load data, order Z and plot
colony <- read.csv("2.1_colony_trial.csv")
colony$Z <- factor(colony$Z, c("None", "Low", "Medium", "High"))
attach(colony)
plot(Count ~ Z)
#Analysis of variance
colony.aov <- aov(Count ~ Z)
print(summary(colony.aov))
#Calculate group means
colony.means <- tapply(Count, Z, mean)
print(colony.means)
barplot(colony.means)
detach(colony)
```
* Make sure you can source your commands (or the file 2.1_colony_1.R) from Rstudio and generate the results and plot.



# Programming Techniques

##Introducing loops

- Many programming languages have ways of doing the same thing many times, perhaps changing some variable each time. This is called *looping*
- Loops are not used in R so often, because we can usually achieve the same thing using vector calculations
- For example, to add two vectors together, we do not need to add each pair of elements one by one, we can just add the vectors
```{r eval=FALSE}
x<- 1:10
y <- 11:20
x+y
```
- But there are some situations where R functions can not take vectors as input. For example, `read.csv` will only load one file at a time
- What if we had ten files to load in, all ending in the same extension (like `.csv`)?

##Introducing loops
- We could do this:

```{r eval=FALSE}
colony  <-data.frame() # Start with empty data frame
colony1 <- read.csv("11_CFA_Run1Counts.csv")
colony2 <- read.csv("11_CFA_Run2Counts.csv")
colony3 <- read.csv("11_CFA_Run3Counts.csv")
  ...
colony10 <- read.csv("11_CFA_Run10Counts.csv")
colony <- rbind(colony1, colony2, colony3, ..., colony10)
```
- But this will be boring to type, difficult to change, and prone to error
- As we are doing the same thing 10 times, but with a different file name each time, we can use a **loop** instead

##Loops: Commands and flow control
- R has two basic types of loop
    + a `for` loop: run some code on every value in a vector
    + a `while` loop: run some code while some condition is true
    
`for` 
```{r loops1, eval=FALSE}
for(i in 1:10){
  print(i)
}
```
`while`
```{r  eval=FALSE}
i <- 1
while ( i <= 10 ) {
   print(i)
   i <- i + 1
}
```

##Loops: Commands and flow control

- Here's how we might use a `for` loop to load in our CSV files
- If the data files are in your current working directory, we can look up files
containing a particular substring in their name using the `dir` function



```{r eval=FALSE}
dir(pattern="Counts.csv")
```

```{r echo=FALSE}
dir("Day_1_scripts/",pattern="Counts.csv")

```

- So we can load all the files using a `for` loop as follows

```{r loops2, eval=FALSE}
colony <- data.frame()
countfiles <- dir(pattern="Counts.csv")
for (file in countfiles) {
   t <- read.csv(file)
   colony <- rbind(colony, t)
}
```

- Here, we use a temporary variable `t` to store the data in each file, and then add that data to the main `colony` data frame.

##Conditional branching: Commands and flow control

- Use an `if` statement for any kind of condition testing
- Different outcomes can be selected based on a condition within brackets

```{r if, eval=FALSE}
if (condition) {
... do this ...
} else {
... do something else ...
}

```

- `condition` is any logical value, and can contain multiple conditions. 
    + e.g. `(a == 2 & b < 5)`, this is a compound conditional argument

##Conditional branching: Commands and flow control
- For example, if we were writing a script to load an unknown set of files, using the `for` loop we wrote before, we might want to warn the user if we can't find any files with the pattern we are searching for. Here's how we can use an `if` statement to test for this

```{r flow-control,eval=FALSE}
colony <- data.frame()
countfiles <- dir(pattern="Counts.csv")
if (length(countfiles) == 0) {
    stop("No Counts.csv files found!")
} else {
    for (file in countfiles) {
        t <- read.csv(file)
        colony <- rbind(colony, t)
    }
}

```

- The `stop` function outputs the error message and quits


##Code formatting avoids bugs!
Compare:
```{r eval=FALSE}
f -26
while(f!=0){
print(letters[f])
f <- f-1}
```
to:
```{r eval=FALSE}
f <- 26
while( f != 0 ){
   print(letters[f])
   f <- f-1
}
```
- The code between brackets `{}` *always* is *indented*, this clearly separates what is executed once, and what is run multiple times
- Trailing bracket `}` always alone on the line at the same indentation level as the initial bracket `{`
- Use white spaces to divide the horizontal space between units of your code, e.g. around assignments, comparisons

##Exercise


- Load in the `colony` data frame using a `for` loop. Three of the data files are in the `Day_1_scripts` folder. Load all three files into `colony` using the for loop in the slides
- How many observations do you have in the colony data frame? Find out by counting the number of rows in `colony` using the `nrow` function
- Suppose a power analysis of your data shows that you only need 48 observations to robustly test your hypothesis. This means we can stop loading files when we have loaded at least 48 observations. Modify your `for` loop so it will only load files if the `colony` data frame has less than 48 observations in it

##Answers to Exercise

- To order the patients by decreasing age
```{r ex3ans1,eval=FALSE}
patients[rev(order(patients$Age)),]
```
- To find the number of rows in the colony data frame
```{r ex3ans2,eval=FALSE}
nrow(colony)
```

- To stop loading files after at least 48 observations have been found, use the code from the first `for` loop slide with a new `if` statement

```{r ex3ans4, eval=FALSE}
colony <- data.frame()
countfiles <- dir(pattern="Counts.csv")
for (file in countfiles) {
    if (nrow(colony) < 48 ) {
        t <- read.csv(file)
        colony <- rbind(colony, t)
    }
}
```



# 5. Data analysis report example

## Combining data from multiple sources: *Gene Clustering Example*

* R has powerful functions to combine heterogeneous data into a single data set
* Gene clustering example data
    + five sets of differentially expressed genes from various experimental conditions
    + file with names of experimentally-verified genes
* Gene clustering exercise
    + combine this dataset into a single table and cluster to see which conditions are similar
    + repeat the clustering but only on a subset of experimentally-verified genes
    
## Combining gene tables

* input files have two columns: gene names and fold change
* we want to combine all five tables into a single table, with 0 for missing values
![gene-tables](images/gene-tables.png)

## Gene Clustering: Script Walkthrough 1

* To make the big table we first need to find out all the genes present in at least one of the files
* Make sure not to use factors in `read.delim()`
    + when loading in character data, use `as.is=TRUE` to prevent it being converted to factors
    + `union()` is a set operation which combines two vectors by eliminating duplicates. See also `intersect` and `setdiff`

```{r eval=FALSE}
#start with an empty collection of genes
genes <- c()
for(fileNum in 1:5){
  #load in files 2_3.DiffGenes1.tsv...
  t <- read.delim(paste("2.3_DiffGenes", fileNum, ".tsv"
                        , sep="")
                  , as.is=TRUE, header=FALSE)
  #label the input columns to help code readability
  names(t) <- c("gene", "expression")
  genes <- union(genes, t$gene)
}
#for tidiness order our genes by name
genes <- sort(genes)
genes #show all genes
```
- *Example code: 2.3_geneClustering.R*

## Gene Clustering: Script Walkthrough 2

* Using the complete list of genes, we can create the big table and fill in the values:
    + `match()` returns the index of the first argument in the second. i.e. index of input file genes in the big table
    + we use index to pick the rows in such way that they match the order in the input file
    
```{r eval=FALSE}
#make the destination table [rows=unique genes,cols=file numbers]
values <- matrix(0, nrow=length(genes), ncol=5)
rownames(values) <- genes
for(fileNum in 1:5){
  #read in the file again
    t <- read.delim(paste("2.3_DiffGenes", fileNum,".tsv"
                        , sep=""), as.is=TRUE, header=FALSE)
    names(t) <- c("gene","expression")
    index <- match(t$gene, rownames(values))
    values[index,fileNum] <- t$expression
}
```

## Gene Clustering: Script Walkthrough 3

* Now we can do hierarchical clustering:
    + Values from the matrix are colour-coded. Rows and columns are re-arranged according to similarity

```{r eval=FALSE,fig.height=4}
heatmap(values, scale="none", col=cm.colors(256))
```

```{r echo=FALSE}
setwd("Day_2_scripts/")
genes <- c()
for(fileNum in 1:5){
  t <- read.delim(paste("2.3_DiffGenes", fileNum, ".tsv"
                        , sep="")
                  , as.is=TRUE, header=FALSE)
  names(t) <- c("gene", "expression")
  genes <- union(genes, t$gene)
}
genes <- sort(genes)
values <- matrix(0, nrow=length(genes), ncol=5)
rownames(values) <- genes
for(fileNum in 1:5){
    t <- read.delim(paste("2.3_DiffGenes", fileNum, ".tsv"
                        , sep=""), as.is=TRUE, header=FALSE)
    names(t) <- c("gene", "expression")
    index <- match(t$gene, rownames(values))
    values[index, fileNum] <- t$expression
}
heatmap(values, scale="none", col=cm.colors(256))

```

## Gene Clustering: Script Walkthrough 4 

* In a second part of our analysis, we want to produce the same heatmap but only based on a list of experimentally-verified genes
* The problem is that the data are not formatted in the most convenient way:

![gene-lists](images/gene-lists.png)


## Gene Clustering: Script Walkthrough 5

* We load in this table, and only extract the gene names, then we use them to select a subset of the `values` matrix
```{r eval=FALSE}
t.exp <- read.delim("2.3_ExperimentalGenes.tsv",
                    as.is=TRUE)
experim.genes <- unlist(strsplit(t.exp$genes, ","))
```
* `unlist` flattens out a nested list into a single vector
* `strsplit` splits a vector of strings by a custom split character (`,`). The result is a list of split values for each element of the input vector
* Now, redo the heatmap by using just the genes in the experimentally verified set  
```{r eval=FALSE}
is.experimental <- rownames(values) %in% experim.genes
heatmap(values[is.experimental,], scale="none"
        , col=cm.colors(256))
```

## Gene Clustering Review

* We load the five tables twice; first to collect gene names, then to load expression values
* Based on the expression table (`values`) we construct a clustered heatmap first on the whole set of genes, then on a selected subset
* Go through the code, try it out and understand it
* Try answering the following questions
    + what is `rownames(values)`
    + why is `rownames(values)[index]` and `t$gene` giving the same output?
    + what is the difference between `rownames(values) %in% experim.genes` and `experim.genes %in% rownames(values)`
  

#References

##References
* Official documentation on:
    + http://cran.r-project.org/manuals.html
* A good repository of R recipes
    + Quick-R: http://www.statmethods.net/
* Don't forget that many packages come with tutorials (vignettes)
* R forums
    + http://stackoverflow.com/questions/tagged/r
    + http://news.gmane.org/gmane.comp.lang.r.general
    
* Plenty of textbooks to choose from, comprehensive list + reviews
    + http://www.r-project.org/doc/bib/R-books.html

#End of Course

##Thanks for your attention

- Please fill-in your feedback so we can improve the course
- The key to learning R is practice, practice, practice!
    + If you don't have your own data yet, look online
    + http://vincentarelbundock.github.io/Rdatasets/datasets.html
- Meet with fellow R users
    + http://www.meetup.com/Cambridge-R-Users-Group-Meetup/
    + informal, quarterly talks
- Look out for an 'Intermediate R' course    

    
